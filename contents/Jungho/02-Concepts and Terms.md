# Concepts and Terms

## Event

- __이벤트란__
  - something happened
  - record 또는 message 라고도 부름
  - Kafka 에서 데이터를 읽거나 쓸 때, 이벤트 형식으로 사용하게 됨
  - __이벤트 구조__
    - 키
    - 값
    - 타임스탬프
    - 기타 메타데이터
    - ```
      Event key: "Alice"
      Event value: "Made a payment of $200 to Bob"
      Event timestamp: "Jun. 25, 2020 at 2:06 p.m."
      ```

## 카프카를 구성하는 주요 요소

- 주키퍼(ZooKeeper): 카프카의 메타데이터(metadata) 관리 및 브로커의 정상상태 점검(health check) 를 담당, 브로커들의 노드 관리 등을 담당
- 카프카(Kafka) or 카프카 클러스터(Kafka Cluster): 여러 대의 브로커를 구성한 클러스터를 의미
- 브로커(Broker): 카프카 애플리케이션이 설치된 서버 또는 노드를 의미
- 프로듀서(Producer, 메시지 생산자): 카프카로 메시지를 보내는 역할을 하는 클라이언트를 총칭
- 컨슈머(Consumer, 메시지 소비자): 카프카에서 메시지를 꺼내가는 역할을 하는 클라이언트를 총칭
- 토픽(topic): 카프카는 메시지 피드들을 토픽으로 구분하고, 각 토픽의 이름은 카프카 내에서 고유함
- 파티션(partition): 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러 개로 나눈 것을 의미
- 세그먼트(segment): 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일을 의미
- 메시지(message) or 레코드(record): 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각을 의미

## 카프카로 메시지를 주고 받는 방법

일반적으로 프로듀서가 카프카로 메시지를 전송할 때 카프카로 그냥 전송하는 것이 아니라, __카프카의 특정 토픽__ 으로 전송하게 된다. 

`kafka-topics.sh` 명령을 사용해 토픽을 생성할 수 있다.

토픽이 생성되었으면 프로듀서를 이용해 메시지를 보낼 준비가 된 것이다. 

### 자주 사용하는 명령어

- kafka-topics.sh: 토픽을 생성하거나 토픽의 설정 등을 변경하기 위해 사용함
- kafka-console-producer.sh: 토픽으로 메시지를 전송하기 위해 사용함. 기본 옵션 외 추가 옵션을 지정할 수 있고, 이를 통해 다양한 프로듀서 옵션 적용 가능
- kafka-console-consumer.sh: 토픽에서 메시지를 가져오기 위해 사용함. 기본 옵션 외 추가 옵션을 지정할 수 있고, 이를 통해 다양한 컨슈머 옵션 적용 가능
- kafka-reassign-partitions.sh: 토픽의 파티션과 위치 변경 등을 위해 사용함.
- kafka-dump.log.sh: 파티션에 저장된 로그 파일의 내용을 확인하기 위해 사용함.

## Replication

> 카프카에서 리플리케이션이란 각 메시지들을 여러 개로 복제해서 카프카 클러스터 내 브로커들에게 분산시키는 동작을 의미. 이러한 리플리케이션 동작 덕분에 하나의 브로커가 종료되더라도 카프카는 `안정성` 을 유지할 수 있다.

- replication-factor: 카프카 내 몇 개의 리플리케이션을 유지하겠다는 의미
  - replication-factor 가 2이면 원본을 포함한 리플리케이션이 총 2개 있다는 의미

- Ex. peter-overview01 이라는 토픽을 리플리케이션 팩터 수 3으로 설정한 후 각 브로커에 배치
  - 토피의 파티션이 리플리케이션 된다.

### Replication factor 수 설정 방법

> 아래는 권장 사항임

- 테스트나 개발환경: 팩터 수를 1로 설정
- 운영 환경(로그성 메시지로서 약간의 유실 허용): 리플리케이션 팩터 수를 2로 설정
- 운영 환경(유실 허용하지 않음): 리플리케이션 팩터 수를 3으로 설정

> 팩터수가 4, 5가 된다면 디스크 공간을 많이 사용하게 되기 때문에, 이 부분을 염두에 두고 늘려야함.

## Partition

> 하나의 토픽이 한 번에 처리할 수 있는 한계를 높이기 위해 토픽 하나를 여러 개로 나눠 병렬 처리가 가능하게 만든 것.

- 파티션 번호는 0부터 시작
- 파티션 수도 토픽을 생성할 때 옵션으로 설정하게 됨
- 파티션 수를 정하는 기준
  - 적절한 파티션 수를 구하는 공식도 간혹 있긴한데, __메시지 크기__ 나 __초당 메시지 건수__ 에 따라 달라지므로 정확하게 예측하기는 힘듦.
  - [Sizing Calculator for Apache Kafka and Confluent Platform](https://eventsizer.io/)
- 파티션 수는 초기 생성 후 언제든 늘릴 수 있지만, __절대로 줄일 수는 없음__ 
  - __따라서 초기에 토픽을 생성할 때 파티션 수를 작게 2, 4 정도로 생성한 후, 메시지 처리량이나 컨슈머의 LAG 등을 모니터링 하면서 조금씩 늘려가는 것이 좋다.__
  - 컨슈머의 LAG 이란
    - `프로듀서가 보낸 메시지 수(카프카에 남아 있는 메시지 수) - 컨슈머가 가져간 메시지 수`
    - 따라서 LAG 이란 지표를 통해 컨슈머에 지연이 없는지 확인할 수 있음
- 프로듀서가 "First Messsage" 라는 메시지를 카프카로 전송하면 해당 메시지는 토픽의 파티션(0~N) 에 저장되어있음
  - 각 메시지는 세그먼트(segment) 라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장됨

## Segment

> 프로듀서가 전송한 메시지는 로컬 브로커의 로컬 디스크에 로그 파일 형태로 안전하게 저장되어 있다.

- __Broker, Partition, Segment 의 관계__
  - Broker : Partition = 1:N
  - Partition : Segment = 1:N
- /kafka-logs 를 통해 확인할 수 있음

```
1. 프로듀서는 카프카의 토픽으로 메시지를 전송한다.
2. 프로듀서로부터 받은 메시지를 파티션의 세그먼트 로그 파일에 저장한다.
3. 브로커의 세그먼트 로그 파일에 저장된 메시지는 컨슈머가 읽어갈 수 있다.
```
